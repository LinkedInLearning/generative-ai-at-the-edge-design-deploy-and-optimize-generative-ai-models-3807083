name: edgelarbs/lab-modep
on:
  push:
  workflow_dispatch:
concurrency:
  group: "${{ github.ref }}"
  cancel-in-progress: true
env:
  HF_ACCESS_TOKEN: "${{ secrets.HF_ACCESS_TOKEN }}"
jobs:
  build:
    runs-on: ubuntu-latest
    container:
      image: ubuntu:latest
    timeout-minutes: 60
    env:
      OLLAMA_API_KEY: "$OLLAMA_API_KEY"
      OLLAMA_SERVER_URL: "$OLLAMA_SERVER_URL"
      HG_UF_MODEL: qwen2.5-0.5b
    steps:
    - uses: actions/checkout@v4.1.0
      with:
        fetch-depth: 20
        lfs: true
    - run: apt update
    - run: apt install -y python3 python3-pip python3-venv git make gcc g++ cmake
    - run: pip3 install --no-cache --upgrade huggingface_hub --break-system-packages
    - run: mkdir -p /root/models
    - run: git config --global credential.helper store
    - run: huggingface-cli login --token $HF_ACCESS_TOKEN --add-to-git-credential
    - run: huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir "/root/models" --include "*"
    - run: ls -ltr /root/models
    - run: git clone https://github.com/ggerganov/llama.cpp.git
    - run: cd llama.cpp
    - run: python3 -m venv .venv
    - run: ". .venv/bin/activate"
    - run: make
    - run: pip3 install --upgrade pip wheel setuptools
    - run: pip3 install --upgrade -r requirements.txt
    - run: python3 convert_hf_to_gguf.py /root/models --outfile /root/models/Qwen2.5-0.5b-f16.gguf --outtype f16
    - run: "./llama-quantize /root/models/Qwen2.5-0.5b-f16.gguf /root/models/MyQwen-model-Q4_K_M.bin Q4_K_M"
    - run: echo "Add code to copy the generated binary file to you artifact repo"
    - run: echo "Build Completed"
  deploy:
    needs: build
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      OLLAMA_API_KEY: "$OLLAMA_API_KEY"
      OLLAMA_SERVER_URL: "$OLLAMA_SERVER_URL"
      HG_UF_MODEL: qwen2.5-0.5b
      HF_ACCESS_TOKEN: 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
    steps:
    - uses: actions/checkout@v4.1.0
      with:
        fetch-depth: 20
        lfs: true
    - run: echo "Add all yopur deploy steps here"
    - run: echo "Deploy Completed"
